{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 22:24:34.686203: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-28 22:24:34.824141: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-28 22:24:34.884462: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-28 22:24:34.901912: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-28 22:24:35.002126: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 22:24:36.174286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722185677.296357   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.427691   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.431587   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.589771   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.591147   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.592518   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 22:24:37.594106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 2612 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1722185677.594724   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.596041   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.597330   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.598651   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185677.599969   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 22:24:37.601285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 2612 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../dataset/Cas16/liver'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m     35\u001b[0m folder_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset/Cas16/liver\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[43mprocess_images_in_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 25\u001b[0m, in \u001b[0;36mprocess_images_in_folder\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mGoes through all files in a folder, opens image files, and prints their dimensions.\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;03m:param folder_path: Path to the folder containing images\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# List all files in the folder\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Construct full file path\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# Check if the file is an image by trying to open it with PIL.Image.open\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../dataset/Cas16/liver'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def get_image_dimensions(image_path):\n",
    "    \"\"\"\n",
    "    Opens an image file and returns its dimensions.\n",
    "    \n",
    "    :param image_path: Path to the image file\n",
    "    :return: A tuple containing the width and height of the image\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            return img.size\n",
    "    except IOError:\n",
    "        print(f\"Error opening {image_path}\")\n",
    "        return None\n",
    "\n",
    "def process_images_in_folder(folder_path):\n",
    "    \"\"\"\n",
    "    Goes through all files in a folder, opens image files, and prints their dimensions.\n",
    "    \n",
    "    :param folder_path: Path to the folder containing images\n",
    "    \"\"\"\n",
    "    # List all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Construct full file path\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Check if the file is an image by trying to open it with PIL.Image.open\n",
    "        dimensions = get_image_dimensions(image_path)\n",
    "        if dimensions:\n",
    "            print(f\"{filename}: {dimensions}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"../dataset/Cas16/liver\"\n",
    "process_images_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722185699.741038   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.744730   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.747777   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.751179   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.754142   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.756695   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.759355   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722185699.761907   12221 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 22:24:59.764434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2612 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722185702.369693   12569 service.cc:146] XLA service 0x7795d4004e90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722185702.369717   12569 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5\n",
      "2024-07-28 22:25:02.453525: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-28 22:25:02.742396: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "E0000 00:00:1722185706.642394   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185706.796790   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185707.319451   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185707.483285   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185708.338059   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185708.502358   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185708.685454   12569 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 1/87\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m18:08\u001b[0m 13s/step - accuracy: 0.7750 - loss: 0.6933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722185712.611028   12569 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m86/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9352 - loss: 0.3382"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1722185722.589848   12570 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185722.739952   12570 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185723.272052   12570 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185723.422182   12570 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1722185723.577263   12570 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.9358 - loss: 0.3368"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 22:25:24.901787: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'input_reduce_select_fusion', 24 bytes spill stores, 36 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 206ms/step - accuracy: 0.9363 - loss: 0.3353 - val_accuracy: 0.9998 - val_loss: 0.1354\n",
      "Epoch 2/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 110ms/step - accuracy: 0.9455 - loss: 0.1333 - val_accuracy: 0.9998 - val_loss: 0.1428\n",
      "Epoch 3/50\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 112ms/step - accuracy: 0.9915 - loss: 0.1059 - val_accuracy: 0.9995 - val_loss: 0.1415\n",
      "Epoch 4/50\n",
      "\u001b[1m67/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m2s\u001b[0m 103ms/step - accuracy: 0.9989 - loss: 0.1058"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# TPU Setup\n",
    "try:\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    strategy = tf.distribute.TPUStrategy(resolver)\n",
    "    print(\"Running on TPU:\", resolver.cluster_spec().as_dict()[\"worker\"])\n",
    "except:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "\n",
    "IMAGE_SIZE = (252, 252)\n",
    "BATCH_SIZE = 16 #* strategy.num_replicas_in_sync\n",
    "\n",
    "def preprocess_image(image_path, liver_mask_path, tumor_mask_path):\n",
    "    def read_image(path):\n",
    "        file = tf.io.read_file(path)\n",
    "        image = tf.image.decode_jpeg(file, channels=1)\n",
    "        image = tf.image.resize(image, (256, 256))  # Resize to nearest multiple of 3\n",
    "        image = tf.image.resize(image, IMAGE_SIZE)  # Resize to exact size\n",
    "        image = tf.cast(image, tf.float32) / 252.0\n",
    "        return image\n",
    "\n",
    "    img = read_image(image_path)\n",
    "    liver_mask = read_image(liver_mask_path)\n",
    "    tumor_mask = read_image(tumor_mask_path)\n",
    "\n",
    "    combined_mask = tf.stack([liver_mask, tumor_mask], axis=-1)\n",
    "    combined_mask = tf.squeeze(combined_mask, axis=2)  # Remove the extra dimension\n",
    "    return img, combined_mask\n",
    "\n",
    "def create_dataset(data_dir, case_ids):\n",
    "    image_paths = []\n",
    "    liver_mask_paths = []\n",
    "    tumor_mask_paths = []\n",
    "\n",
    "    for case_id in case_ids:\n",
    "        case_path = os.path.join(data_dir, case_id)\n",
    "        for file in os.listdir(os.path.join(case_path, 'images')):\n",
    "            image_paths.append(os.path.join(case_path, 'images', file))\n",
    "        for file in os.listdir(os.path.join(case_path, 'liver')):\n",
    "            liver_mask_paths.append(os.path.join(case_path, 'liver', file))\n",
    "        for file in os.listdir(os.path.join(case_path, 'tumor')):\n",
    "            tumor_mask_paths.append(os.path.join(case_path, 'tumor', file))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        image_paths,\n",
    "        liver_mask_paths,\n",
    "        tumor_mask_paths\n",
    "    ))\n",
    "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.shuffle(buffer_size=len(image_paths))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "# Load the dataset\n",
    "all_case_ids = os.listdir('./dataset')\n",
    "train_case_ids = all_case_ids[:int(0.8 * len(all_case_ids))]\n",
    "val_case_ids = all_case_ids[int(0.8 * len(all_case_ids)):]\n",
    "\n",
    "train_dataset = create_dataset('dataset', train_case_ids)\n",
    "val_dataset = create_dataset('dataset', val_case_ids)\n",
    "\n",
    "# Model definition and training\n",
    "inputs = tf.keras.layers.Input(shape=(*IMAGE_SIZE, 1))\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling2D()(x)\n",
    "x = tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.UpSampling2D()(x)\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.UpSampling2D()(x)\n",
    "outputs = tf.keras.layers.Conv2D(2, 3, activation='sigmoid', padding='same')(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"final_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
